{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptos Básicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisar la versión de python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "python_version=platform.python_version()\n",
    "print (python_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(3))\n",
    "print(type(3.0))\n",
    "print(10/3)\n",
    "print(2**5) #potenciación\n",
    "print(9 ** (1/2)) #raíz cuadrada de 9\n",
    "print(20 // 6) # valor entero de la división\n",
    "print(1.25 % 0.5) #operación módulo\n",
    "print(True & False) #operación booleana AND\n",
    "print(True | False) #operación boolena OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precedencia de operadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2 * (3 + 4))\n",
    "print(2*3+4)\n",
    "print(2*3+4>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(float(5))\n",
    "print(int(8.5))\n",
    "print(complex(10))\n",
    "print(bool(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First string\" + \", \" + \"second string\")\n",
    "print(4 * '2')\n",
    "print(\"2\" + \"3\")\n",
    "print(int(\"2\") + int(\"3\"))\n",
    "x=7\n",
    "print(x+3)\n",
    "x += 4\n",
    "print(x)\n",
    "y=\"Machine \"\n",
    "y += \"Learning\"\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"Curso\", \"de\", \"Machine\",\"Learning\"]\n",
    "listavacia=[]\n",
    "numero = 5\n",
    "mezcla = [\"string\", 0, [1, 2, numero], 4.56]\n",
    "nums = [1, 2, 4, 6, 7]\n",
    "nums[2] = 10 \n",
    "\n",
    "print(words[0])\n",
    "print(words[2])\n",
    "print(listavacia)\n",
    "print(mezcla[1])\n",
    "print(mezcla[2])\n",
    "print(mezcla[2][2])\n",
    "print(nums + [4, 5, 6])\n",
    "print(nums * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mercado = (\"pan\", \"huevos\", \"leche\",)\n",
    "my_tupla = \"uno\", \"dos\", \"tres\"\n",
    "tpl = ()\n",
    "\n",
    "print(Mercado[0])\n",
    "print(tpl)\n",
    "Mercado[1] = \"queso\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coloresRGB = {\"red\": [255, 0, 0], \"green\": [0, 255, 0], \"blue\": [0, 0, 255]}\n",
    "edades = {\"David\": 24, \"Maria\": 42, \"John\": 58}\n",
    "edades[\"Diana\"]=18\n",
    "edades[3]=(2,4)\n",
    "\n",
    "\n",
    "print(coloresRGB[\"green\"])\n",
    "print(coloresRGB.get(\"blue\"))\n",
    "print(coloresRGB.get(\"orange\"))\n",
    "print(edades[\"David\"])\n",
    "print(edades)\n",
    "print(\"Diana\" in edades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estructuras de Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=16\n",
    "if x%2 == 0:\n",
    "    print(\"El número \"+str(x)+\" es Par\")\n",
    "else:\n",
    "     print(\"El número \"+str(x)+\" es Inpar\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=10\n",
    "y=20\n",
    "z=5\n",
    "if x<y and x<z:\n",
    "    print(str(x)+\" es el valor más pequeño\")\n",
    "elif y<z:\n",
    "    print(str(y)+\" es el valor más pequeño\")\n",
    "else:\n",
    "    print(str(z)+\" es el valor más pequeño\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras = [\"Hola\", \"estudiantes\", \"curso\", \"verano\"]\n",
    "for x in palabras:\n",
    "    print(x + \"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=64\n",
    "for ans in range(0,x):\n",
    "    if ans**3 == x:\n",
    "        break\n",
    "if ans**3 != x:\n",
    "    print(str(x)+\" no es un cubo perfecto\")\n",
    "else:\n",
    "    print(str(x)+\" es un cubo perfecto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python tiene una estructura for-else que ayuda para estos casos :)\n",
    "x=64\n",
    "for ans in range(0,x):\n",
    "    if ans**3 == x:\n",
    "        print(str(x)+\" es un cubo perfecto\")\n",
    "        break\n",
    "else:\n",
    "    print(str(x)+\" no es un cubo perfecto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=27\n",
    "ans=0\n",
    "while ans**3<x:\n",
    "    ans=ans+1\n",
    "if ans**3 != x:\n",
    "    print(str(x)+\" no es un cubo perfecto\")\n",
    "else:\n",
    "    print(str(x)+\" es un cubo perfecto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteraciones ejercicios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=-27\n",
    "ans=0\n",
    "while ans**3<abs(x):\n",
    "    ans=ans+1\n",
    "if ans**3 != abs(x):\n",
    "    print(str(x)+\" no es un cubo perfecto\")\n",
    "else:\n",
    "    if x<0:\n",
    "        ans=-ans\n",
    "    print(\"La raíz cúbica de \"+str(x)+\" es \"+str(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=-64\n",
    "for ans in range(0,abs(x)):\n",
    "    if ans**3 == abs(x):\n",
    "        break\n",
    "if ans**3 != abs(x):\n",
    "    print(str(x)+\" no es un cubo perfecto\")\n",
    "else:\n",
    "    if x<0:\n",
    "        ans=-ans\n",
    "    print(\"La raíz cúbica de \"+str(x)+\" es \"+str(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrarRaiz(x,n,tol,liminf,limsup):\n",
    "    sol=(liminf+limsup)/2.0\n",
    "    while abs(sol**n-x)>tol:\n",
    "        if sol**n<x:\n",
    "            liminf=sol\n",
    "        else:\n",
    "            limsup=sol\n",
    "        sol=(liminf+limsup)/2.0\n",
    "    return sol\n",
    "print(encontrarRaiz(25.0,2,0.001,0,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones recursivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facto(x):\n",
    "    #función que calcula el factorial \n",
    "    res=1\n",
    "    while x>1:\n",
    "        res=res*x\n",
    "        x-=1\n",
    "    return res\n",
    "print(facto(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factoR(x):\n",
    "    #función que calcula el factorial \n",
    "    if x==1:\n",
    "        return x\n",
    "    return x*factoR(x-1)\n",
    "print(factoR(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal: \n",
    "    def __init__(self, nombre, color):\n",
    "        self.nombre = nombre\n",
    "        self.color = color\n",
    "a=Animal('loqui','negro')\n",
    "print(a.nombre)\n",
    "print(a.color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal: \n",
    "    def __init__(self, nombre, color):\n",
    "        self.nombre = nombre\n",
    "        self.color = color \n",
    "        self.trucos = []    # creates a new empty list for each Animal\n",
    "class Dog(Animal):\n",
    "    tipo = 'mamifero'\n",
    "    def sonido(self):\n",
    "        print(\"Woof!\")\n",
    "    def add_truco(self, truco):\n",
    "        self.trucos.append(truco)\n",
    "        \n",
    "b=Dog('tim','café')\n",
    "b.add_truco('rodar')\n",
    "b.sonido()\n",
    "print(b.tipo)\n",
    "print(b.trucos)\n",
    "\n",
    "a=Dog('sam','negro')\n",
    "a.add_truco('rodar')\n",
    "a.add_truco('dar la mano')\n",
    "a.add_truco('hacerse el muerto')\n",
    "print(b.tipo)\n",
    "print(a.trucos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Regresión Lineal\n",
    "Este ejemplo solamente usa uan caracteristica de un conjuto de datos de diabetes para ilustrar la técnica de regresión en una figura de dos dimensiones. La línea recta en el plot muestra como la regresión lineal encuentra el mejor ajuste que minimiza la suma de cuadrados entre las respuestas observadas en los datos y la predicción hecha por la aproximación lineal. Los coeficientes, la suma de cuadrados y la varianza también son calculados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfitting vs. Overfitting\n",
    "Este ejemplo muestra los problemas de underfitting y overfitting y como podemos usar regresión lineal con características polinomicas para aproximar funciones no lineales. La gráfica muestra la función que queremos aproximar, la cual es una parte de uan función coseno. Adicionalmente, las muestras tomadas de al función real y las aproximaciones de los modelos son mostradas. Los modelos tienen caracteristicas polinomicas de diferentes grados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 30\n",
    "degrees = [1, 4, 15]\n",
    "\n",
    "X = np.sort(np.random.rand(n_samples))\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "for i in range(len(degrees)):\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i],\n",
    "                                             include_bias=False)\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    pipeline.fit(X[:, np.newaxis], y)\n",
    "\n",
    "    # Evaluate the models using crossvalidation\n",
    "    scores = cross_val_score(pipeline, X[:, np.newaxis], y,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "    X_test = np.linspace(0, 1, 100)\n",
    "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\")\n",
    "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n",
    "        degrees[i], -scores.mean(), scores.std()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coeficientes como función de una regularización L2 (Ridge)\n",
    "En este ejemplo la variable dependiente y es función de un conjunto de características de entrada: y=X*w+c. El vector de coeficientes w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Kornel Kielczewski -- <kornel.k@plusnet.pl>\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "clf = Ridge()\n",
    "\n",
    "X, y, w = make_regression(n_samples=10, n_features=8, coef=True,\n",
    "                          random_state=1, bias=3.5) #genera un problema de regresión aleatorio.\n",
    "\n",
    "coefs = []\n",
    "errors = []\n",
    "\n",
    "alphas = np.logspace(-6, 6, 200)\n",
    "\n",
    "# Train the model with different regularisation strengths\n",
    "for a in alphas:\n",
    "    clf.set_params(alpha=a)\n",
    "    clf.fit(X, y)\n",
    "    coefs.append(clf.coef_)\n",
    "    errors.append(mean_squared_error(clf.coef_, w))\n",
    "\n",
    "# Display results\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "\n",
    "plt.subplot(122)\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, errors)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('error')\n",
    "plt.title('Coefficient error as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación de la Densidad de una Mezcla de Gausianas\n",
    "Se grafica la estimación de la densidad de la mezcla de dos gaussianas. Se generan datos para dos gaussianas centradas en diferentes puntos y con matriz de covarianza diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn import mixture\n",
    "\n",
    "n_samples = 300\n",
    "\n",
    "# generate random sample, two components\n",
    "np.random.seed(0)\n",
    "\n",
    "# generate spherical data centered on (20, 20)\n",
    "shifted_gaussian = np.random.randn(n_samples, 2) + np.array([20, 20])\n",
    "\n",
    "# generate zero centered stretched Gaussian data\n",
    "C = np.array([[0., -0.7], [3.5, .7]])\n",
    "stretched_gaussian = np.dot(np.random.randn(n_samples, 2), C)\n",
    "\n",
    "# concatenate the two datasets into the final training set\n",
    "X_train = np.vstack([shifted_gaussian, stretched_gaussian])\n",
    "\n",
    "# fit a Gaussian Mixture Model with two components\n",
    "clf = mixture.GaussianMixture(n_components=2, covariance_type='full')\n",
    "clf.fit(X_train)\n",
    "\n",
    "# display predicted scores by the model as a contour plot\n",
    "x = np.linspace(-20., 30.)\n",
    "y = np.linspace(-20., 40.)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "Z = -clf.score_samples(XX)\n",
    "Z = Z.reshape(X.shape)\n",
    "\n",
    "CS = plt.contour(X, Y, Z, norm=LogNorm(vmin=1.0, vmax=1000.0),\n",
    "                 levels=np.logspace(0, 3, 10))\n",
    "CB = plt.colorbar(CS, shrink=0.8, extend='both')\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], .8)\n",
    "\n",
    "plt.title('Negative log-likelihood predicted by a GMM')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
